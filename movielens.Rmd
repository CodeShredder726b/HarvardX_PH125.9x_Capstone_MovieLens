---
title: "Report on MovieLens and Recommendation System"
subtitle: "HarvardX Data Science Capstone Project"
author: "Raphael Kummer"
date: "`r format(Sys.Date())`"
output: 
  pdf_document:
    df_print: kable
    toc: yes
bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, progress = TRUE, verbose = TRUE)
```

# MovieLens

## Introduction

This is a report on the MovieLens data analysis and a recommendation model training and its performance. First the dataset is to be explored and inspected to evaluate possible training approaches. Next part is building a ML model to recommend movies to users.

### Dataset

Grouplens created a movie rating dataset. The 10M dataset [@harper2015] used in this project is a subset of 10 million ratings of 10'000 movies by 72'000 random selected users.

## Goal

Given is the loading of the MovieLens 10M dataset, split into an *edx* and a *final_holdout_test* set containing 10% of the MovieLens data. The dataset contains userId, movieId, rating, timestamp, title, and genre. This dataset is used to explore and gain insight on how an effective recommendation algorithm could be developed. Such a machine learning algorithm is then developed and tested against the test set.

## Initial Dataset setup

Create edx and final_holdout_test sets from the MovieLens 10M. The final_holdout_test data set should not be used for training, only for evaluating the RMSE.

```{r echo = FALSE, warning = FALSE}
##########################################################
# Create edx and final_holdout_test sets 
##########################################################

# Note: this process could take a couple of minutes

if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")

library(tidyverse)
library(caret)

# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

options(timeout = 120)

dl <- "ml-10M100K.zip"
if(!file.exists(dl))
  download.file("https://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings_file <- "ml-10M100K/ratings.dat"
if(!file.exists(ratings_file))
  unzip(dl, ratings_file)

movies_file <- "ml-10M100K/movies.dat"
if(!file.exists(movies_file))
  unzip(dl, movies_file)

ratings <- as.data.frame(str_split(read_lines(ratings_file), fixed("::"), simplify = TRUE),
                         stringsAsFactors = FALSE)
colnames(ratings) <- c("userId", "movieId", "rating", "timestamp")
ratings <- ratings %>%
  mutate(userId = as.integer(userId),
         movieId = as.integer(movieId),
         rating = as.numeric(rating),
         timestamp = as.integer(timestamp))

movies <- as.data.frame(str_split(read_lines(movies_file), fixed("::"), simplify = TRUE),
                        stringsAsFactors = FALSE)
colnames(movies) <- c("movieId", "title", "genres")
movies <- movies %>%
  mutate(movieId = as.integer(movieId))

movielens <- left_join(ratings, movies, by = "movieId")

# Final hold-out test set will be 10% of MovieLens data
set.seed(1, sample.kind="Rounding") # if using R 3.6 or later
# set.seed(1) # if using R 3.5 or earlier
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in final hold-out test set are also in edx set
final_holdout_test <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

# Add rows removed from final hold-out test set back into edx set
removed <- anti_join(temp, final_holdout_test)
```

# Analysis

## Data Inspection and preprocessing

```{r echo = FALSE}
if(!require(ggplot2)) install.packages("ggplot2")
if(!require(devtools)) install.packages("devtools")
if(!require(benchmarkme)) install.packages("benchmarkme")

library(ggplot2)
library(benchmarkme)
```

The *edx* dataset look like this:

```{r echo = FALSE}
# Add layout of edx data with knitr::kable https://www.rdocumentation.org/packages/knitr/versions/1.41/topics/kable
knitr::kable(head(edx))
```

There are several aspects of the edx dataset to consider exploring: - user ratings in relation to genre - user ratings in relation to movie release year - user ratings in relation to popularity of movies (indie vs blockbuster).

```{r echo=TRUE}
edx[
  ,
  list(
    `Total Movies` = uniqueN(movieId),
    `Total Users` = uniqueN(userId),
    `Total Genres` = uniqueN(genres)
  )
]
```

### Data cleanup

Check if there are any NA in the dataset.

```{r echo=TRUE}
anyNA(edx)
```

There are no missing values in *edx*.

```{r echo=FALSE}
edx %>% group_by(rating) %>% summarise(perc = n()/nrow(edx)) %>% 
  ggplot(aes(rating, perc)) + geom_col() + labs(title = "Rating distribution overall")

#t <- edx %>%
#  group_by(movieId) %>%
#  summarize(m = n()) 

#ggplot(data = t, aes(x = movieId)) + 
#  #geom_bar() +
#  geom_histogram(binwidth = 100) +
#  labs(title = "Ratings per movie")# +
#  #scale_y_log10()
#    #geom_point() #+
#    #geom_histogram(bins = 25, binwidth=0.2, color="blue", show.legend = FALSE, aes(fill = cut(n, 100))) + 
#    #labs(title = "Ratings per movie")
```

Is the rating of movies dependent of release year of the movie?

```{r echo=TRUE}
#mutate()
```

Is the rating dependant of genre? (Of a user. e.g. UserX has 90% of rated movies in the genre of Comedy, he is more likely to rate a Comedy better than Action or Crime)

```{r echo=TRUE}
#edx_genres <- edx %>% mutate(comedy = )

edx %>% 
  group_by(genres) %>% 
  summarise(perc = n()/nrow(edx)) %>% 
    ggplot(aes(genres, perc)) + 
    geom_col() + 
    labs(title = "Genres distribution overall")
```

-   check user ratings vs different genres

-   ...

# Model

## Results

### RMSE

# Conclusion

-   summary
-   limitations

### Future Improvements
Further information about the users could imporve accuracy, e.g. shopping preferences, music taste, background infourmation like education level. But there privacy concern about the usage of user personal data has to be considered. Training with larger dataset would be beneficial but would require more capable systems (e.g. with GPU). 

# System

## Hardware

All above computations are done with an `r {get_cpu().model_name}` CPU with `r {get_cpu().no_of_cores}` and `r {get_ram()}`` of RAM.

```{r}
#get_cpu()
#get_ram()
```

## Software

This report is compiled using R markdown with RStudio.

```{r}
sessionInfo()
```

## Resources

[1] Rafael Irizarry. 2018. Introduction to Data Science. <https://rafalab.dfci.harvard.edu/dsbook/>
